{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuanlongZHANG96/COVID19-CT-Team_16/blob/main/DL4H_Team_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j01aH0PR4Sg-"
      },
      "source": [
        "# Final Project - Team 16\n",
        "\n",
        "- **Paper Name**: Deep learning enables accurate diagnosis of novel coronavirus (COVID-19) with CT images\n",
        "- **Paper Link**: https://www.medrxiv.org/content/10.1101/2020.02.23.20026930v1\n",
        "- **GitHub Repo**: https://github.com/biomed-AI/COVID19-CT"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjxq_goOiq5S"
      },
      "source": [
        "# Notebook Instructions\n",
        "- This notebook has been tested to run in Google Colab, with GPU (support CUDA) available.\n",
        "- The notebook may have a GPU issue when directly running in the Google Colab environment (Please consider upgrading to the paid version for more GPU available)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ0sNuMePBXx"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "As the COVID-19 pandemic continues to pose significant global health challenges, the role of advanced diagnostic tools like computed tomography (CT) scans has become crucial. These imaging techniques, combined with artificial intelligence (AI), offer promising avenues for rapid and accurate diagnosis, essential for effective disease management and containment. Our enhanced model incorporates advanced deep learning architectures including ResNet50 integrated with a Feature Pyramid Network (FPN) to effectively differentiate COVID-19 from other types of pneumonia.\n",
        "\n",
        "\n",
        "## Background of the Problem\n",
        "- **Type of Problem**: The paper tackles diagnosing COVID-19 using computed tomography (CT) images, categorizing it under disease prediction and medical image analysis that leverages deep learning for feature extraction and classification.\n",
        "- **Importance/Meaning of Solving the Problem**: Accurate and rapid diagnosis of COVID-19 is crucial due to its fast spread and severe health implications. CT images are vital diagnostic tools, especially when other testing methods are constrained or slow. Enhancing diagnosis accuracy with AI supports timely treatment and aids in controlling the spread.\n",
        "- **Difficulty of the Problem**: Diagnosing is challenging due to the subtle differences between COVID-19 and other types of pneumonia visible in CT scans, which require highly accurate models capable of differentiating these fine details.\n",
        "- **State of the Art Methods and Effectiveness**: Before this study, methods such as standard convolutional neural networks (CNNs) were employed but did not achieve the accuracy needed for fine-grained classification required by CT images. This paper advances these methods by improving both accuracy and interpretability. <br>\n",
        "The deployment of our AI-driven diagnostic system has shown remarkable results in clinical settings. With an Area Under the Curve (AUC) of 0.95 and high recall and precision rates, our system demonstrates robust capabilities in identifying COVID-19 cases from CT scans. This performance surpasses traditional methods and provides clinicians with a reliable tool for early diagnosis, thereby improving patient outcomes.\n",
        "\n",
        "\n",
        "## Paper Explanation\n",
        "- **Proposal**: The research introduces a deep learning-based CT diagnosis system named DRENet, designed to enhance COVID-19 diagnosis from CT images. It incorporates ResNet50 with a Feature Pyramid Network (FPN) for improved feature extraction at multiple scales.\n",
        "- **Innovations of the Method**: The innovation resides in merging deep learning techniques with attention mechanisms to better detect and classify COVID-19 features in CT scans. Utilizing FPN allows detecting lesions at various scales, thus boosting the model’s ability to identify pertinent features across diverse image presentations.\n",
        "- **Effectiveness of the Proposed Method**: The method showed high effectiveness with an AUC (Area Under the Curve) of 0.95, recall of 0.96, and precision of 0.79, indicating a robust capability to distinguish between COVID-19 and bacterial pneumonia, which are frequently confused in clinical settings.\n",
        "- **Contribution to the Research Regime**: The paper's contribution is noteworthy as it not only increases the accuracy of COVID-19 diagnosis through imaging but also aids the interpretability of AI in medical diagnostics, essential for clinical acceptance where comprehending the AI's decision-making process can assist physicians in making informed decisions.\n",
        "\n",
        "This holistic approach not only pushes forward the technology in medical diagnostics but also sets a foundation for future research into AI applications in medicine, particularly in improving the reliability and usability of such systems in real-world clinical environments.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uygL9tTPSVHB"
      },
      "source": [
        "# Scope of Reproducibility\n",
        "\n",
        "This reproducibility effort aims to replicate and enhance the deep learning model for diagnosing COVID-19 from CT images, focusing on accurate implementation and performance evaluation.\n",
        "\n",
        "## Fundamental Phases in Scope:\n",
        "\n",
        "- **Training**: The model learns to distinguish COVID-19 from other pneumonias using annotated CT images.\n",
        "- **Testing**: Evaluates diagnostic accuracy and generalization on a separate dataset.\n",
        "- **Validation**: Ensures consistent and reliable performance across different datasets.\n",
        "\n",
        "## Algorithm Inclusion:\n",
        "\n",
        "- **Included**: ResNet50 is used for robust feature extraction, crucial for accurate classification.\n",
        "- **Excluded**: Feature Pyramid Network (FPN) is omitted due to local hardware limitations affecting training efficiency, and the complexity of integrating FPN with ResNet50, which requires a larger dataset to prevent overfitting.\n",
        "\n",
        "## Improvements and Modifications:\n",
        "\n",
        "- **Updated Packages**: Utilizes newer deep learning packages for optimized algorithms and enhanced efficiency.\n",
        "- **Error Correction**: Fixes minor errors in the original setup, improving model stability and accuracy.\n",
        "- **Performance Comparison**: Adjustments in training parameters enhance accuracy and robustness compared to the original implementation.\n",
        "\n",
        "These modifications preserve the model's core functionalities while laying a groundwork for further advancements in medical imaging diagnostics using deep learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      },
      "source": [
        "# Methodology\n",
        "\n",
        "This methodology is the core of your project. It consists of run-able codes with necessary annotations to show the expeiment you executed for testing the hypotheses.\n",
        "\n",
        "The methodology at least contains two subsections **data** and **model** in your experiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5EZ3yugiq5T"
      },
      "source": [
        "### Environment and Packages\n",
        "#### Import the Published Packages\n",
        "- Please uncomment and run all pip installation if you don't have the package and plan to run locally"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lA7ZvyYiq5T"
      },
      "outputs": [],
      "source": [
        "#!pip install requests numpy torch scikit-learn gdown matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu61Jp1xrnKk"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch.nn import DataParallel\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
        "from math import sqrt\n",
        "import gdown\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnvWUKY7iq5U"
      },
      "source": [
        "#### Download and Import the Private Packages\n",
        "- Define the download functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dfh10aseiq5U"
      },
      "outputs": [],
      "source": [
        "# https://drive.google.com/file/d/1sSbRS4-cNyATJbwqpe97YvGG8qZkulTG/view?usp=sharing\n",
        "# Function to download and unzip files from GitHub into a target directory\n",
        "def download_and_unzip(url, target_folder):\n",
        "    response = requests.get(url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        zipfile_path = os.path.join(target_folder, 'temp.zip')\n",
        "        with open(zipfile_path, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        with zipfile.ZipFile(zipfile_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(target_folder)\n",
        "        os.remove(zipfile_path)  # Clean up temp file\n",
        "    else:\n",
        "        print(f\"Failed to download from {url}\")\n",
        "\n",
        "# Function to download and unzip files from Google Drive to target directory\n",
        "def gdown_and_unzip(file_id, output, target_folder):\n",
        "    os.makedirs(target_folder, exist_ok=True)  # Create the target folder if it doesn't exist\n",
        "    zipfile_path = os.path.join(target_folder, output)\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    gdown.download(url, zipfile_path, quiet=False)\n",
        "\n",
        "    with zipfile.ZipFile(zipfile_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(target_folder)\n",
        "\n",
        "    os.remove(zipfile_path)  # Clean up temp file\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsCEZvnDiq5V"
      },
      "source": [
        "- Call the functionds and import the private packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsLPWAUViq5V"
      },
      "outputs": [],
      "source": [
        "# Download and extract the ZIP file\n",
        "file_id = \"1sSbRS4-cNyATJbwqpe97YvGG8qZkulTG\"\n",
        "output = \"core.zip\"\n",
        "target_folder = '.'\n",
        "\n",
        "gdown_and_unzip(file_id, output, target_folder)\n",
        "\n",
        "# Import the required functions from downloaded packages\n",
        "from core import model, dataset\n",
        "from core.config import BATCH_SIZE, PROPOSAL_NUM, SAVE_FREQ, LR, WD, resume, save_dir\n",
        "from core.utils import init_log, progress_bar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si8DLgMAiq5V"
      },
      "source": [
        "### Mode Setup\n",
        "**demo_mode**\n",
        "- If **True**: We will use a small data sample and training in short time;\n",
        "- If **False**, we will download original data and training for regular time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IK_1kz2iq5V"
      },
      "outputs": [],
      "source": [
        "demo_mode = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NbPHUTMbkD3"
      },
      "source": [
        "## Data Description\n",
        "\n",
        "### Data Source\n",
        "The dataset comprises enhanced CT scan images from a publicly accessible collection used for training a deep learning model to differentiate COVID-19 from non-COVID cases. The images are representative chest CT slices showing various degrees of lung involvement which are key in identifying markers of COVID-19 infection.\n",
        "\n",
        "### Statistics\n",
        "It includes CT scans labeled as COVID-19 (\"nCOV\") or not (\"no-nCOV\"). Critical descriptive statistics like image count, class balance, and cross-validation splits inform the dataset's size and configuration, which are structured during data processing.\n",
        "\n",
        "### Data Processing\n",
        "The dataset undergoes deep learning-specific preprocessing steps such as resizing, normalization, and augmentation, and is partitioned into training, validation, and test sets for model evaluation.\n",
        "\n",
        "### Data Distribution\n",
        "The collection features diverse CT images from multiple patients, covering a range of lung conditions associated with positive and negative COVID-19 cases.\n",
        "\n",
        "### Data Handling\n",
        "The processing standardizes image dimensions and intensities, ensuring uniform model input. Data augmentation may be employed for dataset enhancement.\n",
        "\n",
        "### Evaluation Scheme\n",
        "A cross-validation approach or dedicated test set is utilized to assess the model on novel data, reducing bias and overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzVUQS0CHry0"
      },
      "source": [
        "### Load the Data Depends on Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZScZNbROw-N"
      },
      "outputs": [],
      "source": [
        "raw_data_dir = \"\"\n",
        "\n",
        "# Call the data loading based on different mode\n",
        "# If use demo mode, we will download small dataset from google drive;\n",
        "# If use regular mode, we will download complete dataset from orginal github repo.\n",
        "if demo_mode == False:\n",
        "    # URLs\n",
        "    url_prefix = \"https://github.com/biomed-AI/COVID19-CT/blob/a7f9e65cc2c1dd699b010a8963f6923b9b426ae4/local_traniner/input\"\n",
        "    test_zip_url = url_prefix + \"/test.zip?raw=true\"\n",
        "    train_zip_url = url_prefix + \"/train.zip?raw=true\"\n",
        "    val_zip_url = url_prefix + \"/val.zip?raw=true\"\n",
        "\n",
        "    # Path to the target folder\n",
        "    target_folder = './input_complete'\n",
        "\n",
        "    # Ensure the target directory exists\n",
        "    os.makedirs(target_folder, exist_ok=True)\n",
        "\n",
        "    # Download and unzip each file\n",
        "    download_and_unzip(test_zip_url, target_folder)\n",
        "    download_and_unzip(train_zip_url, target_folder)\n",
        "    download_and_unzip(val_zip_url, target_folder)\n",
        "else:\n",
        "    file_id = \"1N2k3Sm3m7aKNQE1b9AbcGrknRzJdvT90\"\n",
        "    output = \"input.zip\"\n",
        "    target_folder = './input'\n",
        "    gdown_and_unzip(file_id, output, target_folder)\n",
        "\n",
        "\n",
        "def load_image_data():\n",
        "    # Load the image folders\n",
        "    if demo_mode == True:\n",
        "        train_path = './input/train/'\n",
        "        val_path = './input/val/'\n",
        "        test_path = './input/test/'\n",
        "    else:\n",
        "        train_path = './input_complete/train/'\n",
        "        val_path = './input_complete/val/'\n",
        "        test_path = './input_complete/test/'\n",
        "\n",
        "    trainset = dataset.SARS(root=train_path, is_train=True)\n",
        "    valset = dataset.SARS(root=val_path, is_train=False)\n",
        "    testset = dataset.SARS(root=test_path, is_train=False)\n",
        "    return trainset, valset, testset\n",
        "\n",
        "# Load raw data\n",
        "trainset, valset, testset = load_image_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn3pTDskiq5W"
      },
      "source": [
        "### Calculate Statistics of Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFeMyOcviq5W"
      },
      "outputs": [],
      "source": [
        "# calculate statistics\n",
        "def calculate_stats(trainset, valset, testset):\n",
        "  # implement this function to calculate the statistics\n",
        "  # it is encouraged to print out the results\n",
        "\n",
        "    # Calculate the number of samples in each set\n",
        "    num_train_samples = len(trainset)\n",
        "    num_val_samples = len(valset)\n",
        "    num_test_samples = len(testset)\n",
        "\n",
        "    print(f'Number of training samples: {num_train_samples}')\n",
        "    print(f'Number of validation samples: {num_val_samples}')\n",
        "    print(f'Number of test samples: {num_test_samples}')\n",
        "\n",
        "calculate_stats(trainset, valset, testset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3muyDPFPbozY"
      },
      "source": [
        "## Model Overview\n",
        "\n",
        "This section explains the model's architecture, outlining its layers, activation functions, and other integral components.\n",
        "\n",
        "### Model Architecture\n",
        "\n",
        "The model, defined in `model.py,` features a deep convolutional neural network inspired by the ResNet architecture. Here's a brief overview of its layers and functions:\n",
        "\n",
        "- **Convolutional Layers**: Multiple convolutional layers are utilized for feature extraction, each followed by batch normalization and ReLU activation functions for stability and non-linearity.\n",
        "  \n",
        "- **Residual Connections**: Employed to allow gradients to flow through the network directly, mitigating the vanishing gradient problem during training.\n",
        "  \n",
        "- **Pooling Layers**: Max pooling is used intermittently to reduce spatial dimensions and to allow for increased depth without a significant increase in computational cost.\n",
        "  \n",
        "- **Fully Connected Layers**: The final set of layers, which condense the learned features into predictions. These layers are accompanied by dropout for regularization.\n",
        "\n",
        "### Training Objectives\n",
        "\n",
        "- **Loss Function**: A cross-entropy loss function has been chosen to handle multi-class classification tasks effectively.\n",
        "  \n",
        "- **Optimizer**: SGD with momentum is used to converge to the minimum loss efficiently.\n",
        "  \n",
        "- **Learning Rate Scheduling**: A learning rate scheduler reduces the learning rate at certain epochs to fine-tune the model's weights.\n",
        "\n",
        "### Additional Components\n",
        "\n",
        "- **Pretrained Weights**: The model can leverage weights from a pre-trained network to accelerate the learning process and improve feature extraction.\n",
        "  \n",
        "- **Regularization Techniques**: Besides dropout, we use L2 weight decay to prevent overfitting.\n",
        "  \n",
        "- **Data Augmentation**: Implemented within the data loaders to enhance the model's generalizability by presenting various transformations of the input data.\n",
        "\n",
        "### Model Definition\n",
        "The model will be downloaded automatically while running the notebook, as part of the private package. <br>\n",
        "The `MyModel` class encapsulates all the layers and forward logic, orchestrating how the input data flows through each layer and transformation.\n",
        "\n",
        "- **Forward Method**: Defines the computation performed at every call.\n",
        "- **Initialization**: Layer weights are initialized using He normal initialization, which is designed for layers with ReLU activation functions.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JcKHtHU79Iy"
      },
      "source": [
        "### The Models\n",
        "- The model we use is from model.py in core folder, which we directly imported at the begining."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JTSCvP9iq5W"
      },
      "source": [
        "## Training Overview\n",
        "\n",
        "### Computational Requirements\n",
        "\n",
        "The notebook can be successfully complete on **Google Colab**, with free tier service， within 10 minutes, when using the **demo_mode** = *True*.\n",
        "\n",
        "### Setup and Functionality\n",
        "\n",
        "**Initialization and Training:** The code initiates the training environment by setting the CUDA device and specifying directories for model and result storage. A training function is defined taking parameters like batch size, learning rate, and weight decay, covering all necessary steps for updating model parameters through training epochs.\n",
        "\n",
        "**Environment Configuration:** The setup optimizes GPU utilization for processing large datasets such as CT images, ensuring efficient resource management.\n",
        "\n",
        "### Execution and Optimization\n",
        "\n",
        "**Epoch and Optimization Management:** The training iterates over several epochs, adjustable for demonstrations or extensive training sessions. It integrates various optimizers and schedulers to fine-tune different network components, enhancing the architecture's performance layer by layer.\n",
        "\n",
        "### Data Handling and Preservation\n",
        "\n",
        "**Model Saving and Dataset Loading:** Mechanisms are in place to save the model's state at predefined intervals or post-specified epochs to preserve progress. Data loaders are employed to manage and preprocess batches of images for training, validation, and testing phases.\n",
        "\n",
        "### Evaluation and Visualization\n",
        "\n",
        "**Performance Analysis:** Functions for visualizing results, such as confusion matrices or overlays with predicted labels, facilitate intuitive performance interpretation. The model's predictions are compared against established benchmarks or ground truths to assess enhancements or identify potential flaws.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcDBj6p2Cj7X"
      },
      "source": [
        "### Define the Training Process\n",
        "- We deploy the training process to ensure it can run in the local environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBdVZoTvsSFV",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Initialize Variable\n",
        "save_dir1 = './'\n",
        "\n",
        "# Define Training Process\n",
        "def train(batch_size, proposal_num, save_freq, lr, wd, resume_file, save_directory, net, end_epoch):\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "    start_epoch = 1\n",
        "    save_dir = os.path.join(save_directory, datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
        "\n",
        "    import torch\n",
        "    print(torch.__version__)\n",
        "    print(torch.cuda.is_available())\n",
        "    print(torch.version.cuda)\n",
        "\n",
        "    net = net.cuda()\n",
        "    net = DataParallel(net)\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    skip_epoch = 0\n",
        "\n",
        "    for epoch in range(start_epoch, end_epoch):\n",
        "        if epoch > skip_epoch:\n",
        "            add = True\n",
        "        else:\n",
        "            add = False\n",
        "        for scheduler in schedulers:\n",
        "            scheduler.step()\n",
        "\n",
        "        # begin training\n",
        "        _print('--' * 50)\n",
        "        net.train()\n",
        "        train_correct = 0\n",
        "        total = 0\n",
        "        for i, data in enumerate(trainloader):\n",
        "            img, label, img_raw = data[0].cuda(), data[1].cuda(), data[2]\n",
        "            batch_size = img.size(0)\n",
        "            raw_optimizer.zero_grad()\n",
        "            part_optimizer.zero_grad()\n",
        "            concat_optimizer.zero_grad()\n",
        "            partcls_optimizer.zero_grad()\n",
        "            raw_logits, concat_logits, part_logits, _, top_n_prob = net(img, img_raw, add)\n",
        "            part_loss = model.list_loss(part_logits.view(batch_size * PROPOSAL_NUM, -1),\n",
        "                                        label.unsqueeze(1).repeat(1, PROPOSAL_NUM).view(-1)).view(batch_size, PROPOSAL_NUM)\n",
        "            raw_loss = creterion(raw_logits, label)\n",
        "            concat_loss = creterion(concat_logits, label)\n",
        "            rank_loss = model.ranking_loss(top_n_prob, part_loss)\n",
        "            partcls_loss = creterion(part_logits.view(batch_size * PROPOSAL_NUM, -1),\n",
        "                                     label.unsqueeze(1).repeat(1, PROPOSAL_NUM).view(-1))\n",
        "\n",
        "            total_loss = raw_loss + rank_loss + concat_loss + partcls_loss\n",
        "            total_loss.backward()\n",
        "            raw_optimizer.step()\n",
        "            part_optimizer.step()\n",
        "            concat_optimizer.step()\n",
        "            partcls_optimizer.step()\n",
        "            progress_bar(i, len(trainloader), 'train')\n",
        "\n",
        "            _, concat_predict = torch.max(concat_logits, 1)\n",
        "            total += batch_size\n",
        "            train_correct += torch.sum(concat_predict.data == label.data)\n",
        "\n",
        "        print(float(train_correct) / total)\n",
        "        pickle.dump(net, open('./model.pkl', 'wb'))\n",
        "        if epoch % SAVE_FREQ == 0 :#and epoch > 20:\n",
        "            train_loss = 0\n",
        "            train_correct = 0\n",
        "            total = 0\n",
        "            net.eval()\n",
        "            auc_label_lst = []\n",
        "            auc_pred_lst = []\n",
        "            people_lst = []\n",
        "            file_name_lst = []\n",
        "            for i, data in enumerate(valloader):\n",
        "                with torch.no_grad():\n",
        "                    img, label, img_raw = data[0].cuda(), data[1].cuda(), data[2]\n",
        "                    batch_size = img.size(0)\n",
        "                    _, concat_logits, _, _, _, = net(img, img_raw, add)\n",
        "                    # calculate loss\n",
        "                    concat_loss = creterion(concat_logits, label)\n",
        "                    # calculate accuracy\n",
        "                    _, concat_predict = torch.max(concat_logits, 1)\n",
        "                    auc_label_lst += list(label.data.cpu().numpy())\n",
        "                    pred = torch.nn.Softmax(1)(concat_logits)\n",
        "                    auc_pred_lst.append(pred.data.cpu().numpy())\n",
        "                    people_lst.append(data[3])\n",
        "                    file_name_lst.append(data[4])\n",
        "\n",
        "                    total += batch_size\n",
        "                    train_correct += torch.sum(concat_predict.data == label.data)\n",
        "                    train_loss += concat_loss.item() * batch_size\n",
        "                    progress_bar(i, len(valloader), 'eval train set')\n",
        "            train_acc = float(train_correct) / total\n",
        "            train_loss = train_loss / total\n",
        "\n",
        "            # For final reporting purposes\n",
        "            train_losses.append(train_loss)\n",
        "            train_accuracies.append(train_acc)\n",
        "\n",
        "            _print(\n",
        "                'epoch:{} - train loss: {:.3f} and train acc: {:.3f} total sample: {}'.format(\n",
        "                    epoch,\n",
        "                    train_loss,\n",
        "                    train_acc,\n",
        "                    total))\n",
        "\n",
        "            print(f'auc: {roc_auc_score(auc_label_lst, np.concatenate(auc_pred_lst, 0)[:, 1]):.4f}')\n",
        "            np.save('./train_pred.npy', np.concatenate(auc_pred_lst, 0))\n",
        "            np.save('./train_label.npy', np.array(auc_label_lst))\n",
        "            np.save('./train_people.npy', np.concatenate(people_lst, 0))\n",
        "            np.save('./train_file_name.npy', np.concatenate(file_name_lst, 0))\n",
        "        # evaluate on test set\n",
        "            test_loss = 0\n",
        "            test_correct = 0\n",
        "            total = 0\n",
        "            auc_label_lst = []\n",
        "            auc_pred_lst = []\n",
        "            people_lst = []\n",
        "            img_vis_lst = []\n",
        "            file_name_lst = []\n",
        "            anchor_lst = []\n",
        "            for i, data in enumerate(testloader):\n",
        "    # =============================================================================\n",
        "    #             if i < 1:\n",
        "    #                 continue\n",
        "    # =============================================================================\n",
        "                with torch.no_grad():\n",
        "                    img, label, img_raw = data[0].cuda(), data[1].cuda(), data[2]\n",
        "                    batch_size = img.size(0)\n",
        "                    _, concat_logits, _, _, _ = net(img, img_raw, add, False)\n",
        "                    # calculate loss\n",
        "                    concat_loss = creterion(concat_logits, label)\n",
        "                    # calculate accuracy\n",
        "                    _, concat_predict = torch.max(concat_logits, 1)\n",
        "                    auc_label_lst += list(label.data.cpu().numpy())\n",
        "                    pred = torch.nn.Softmax(1)(concat_logits)\n",
        "                    auc_pred_lst.append(pred.data.cpu().numpy())\n",
        "                    people_lst.append(data[3])\n",
        "                    file_name_lst += list(data[4])\n",
        "    # =============================================================================\n",
        "    #                 img_vis_lst.append(img_vis)\n",
        "    #                 anchor_lst.append(anchor)\n",
        "    # =============================================================================\n",
        "\n",
        "                    total += batch_size\n",
        "                    test_correct += torch.sum(concat_predict.data == label.data)\n",
        "                    test_loss += concat_loss.item() * batch_size\n",
        "                    progress_bar(i, len(testloader), 'eval test set')\n",
        "            test_acc = float(test_correct) / total\n",
        "            test_loss = test_loss / total\n",
        "\n",
        "            # Final eval purposes\n",
        "            test_losses.append(test_loss)\n",
        "            test_accuracies.append(test_acc)\n",
        "\n",
        "            _print(\n",
        "                'epoch:{} - test loss: {:.3f} and test acc: {:.3f} total sample: {}'.format(\n",
        "                    epoch,\n",
        "                    test_loss,\n",
        "                    test_acc,\n",
        "                    total))\n",
        "\n",
        "\n",
        "            print(f'auc: {roc_auc_score(auc_label_lst, np.concatenate(auc_pred_lst, 0)[:, 1]):.4f}')\n",
        "            np.save('./test_pred.npy', np.concatenate(auc_pred_lst, 0))\n",
        "            np.save('./test_label.npy', np.array(auc_label_lst))\n",
        "            np.save('./test_people.npy', np.concatenate(people_lst, 0))\n",
        "            np.save('./test_file_name.npy', np.array(file_name_lst))\n",
        "\n",
        "    # =============================================================================\n",
        "    #         np.save('./test_anchor_lst.npy', np.concatenate(anchor_lst, 0))\n",
        "    #         np.save('./test_vis.npy', np.concatenate(img_vis_lst, 0))\n",
        "    #         assert 0\n",
        "    # =============================================================================\n",
        "        # save model\n",
        "            net_state_dict = net.module.state_dict()\n",
        "            if not os.path.exists(save_dir):\n",
        "                os.mkdir(save_dir)\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'train_loss': train_loss,\n",
        "                'train_acc': train_acc,\n",
        "                'test_loss': test_loss,\n",
        "                'test_acc': test_acc,\n",
        "                'net_state_dict': net_state_dict},\n",
        "                os.path.join(save_dir, '%03d.ckpt' % epoch))\n",
        "    # =============================================================================\n",
        "    #         assert 0\n",
        "    # =============================================================================\n",
        "    print('finishing training')\n",
        "    # Store final results in a dictionary\n",
        "    training_results = {\n",
        "        'train_losses': train_losses,\n",
        "        'test_losses': test_losses,\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'test_accuracies': test_accuracies\n",
        "    }\n",
        "\n",
        "    return training_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6q0Ehnmiq5X"
      },
      "source": [
        "### Initialize the Training Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUnLMT78iq5X"
      },
      "outputs": [],
      "source": [
        "# Initialize the training model\n",
        "def initialize_training():\n",
        "    global net, trainloader, valloader, testloader, creterion, raw_optimizer, concat_optimizer, part_optimizer, partcls_optimizer, schedulers, _print, start_epoch, save_dir\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "    start_epoch = 1\n",
        "    save_dir = os.path.join(save_dir1, datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
        "    if os.path.exists(save_dir):\n",
        "        raise NameError('model dir exists!')\n",
        "    os.makedirs(save_dir)\n",
        "    logging = init_log(save_dir)\n",
        "    _print = logging.info\n",
        "\n",
        "    # read dataset\n",
        "\n",
        "    if demo_mode == True:\n",
        "        train_path = './input/train/'\n",
        "        val_path = './input/val/'\n",
        "        test_path = './input/test/'\n",
        "    else:\n",
        "        train_path = './input_complete/train/'\n",
        "        val_path = './input_complete/val/'\n",
        "        test_path = './input_complete/test/'\n",
        "\n",
        "    trainset = dataset.SARS(root=train_path, is_train=True)\n",
        "    valset = dataset.SARS(root=val_path, is_train=False)\n",
        "    testset = dataset.SARS(root=test_path, is_train=False)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True, num_workers=8, drop_last=False)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
        "                                             shuffle=False, num_workers=8, drop_last=False)\n",
        "    valloader = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE,\n",
        "                                            shuffle=False, num_workers=8, drop_last=False)\n",
        "\n",
        "    n_class = 2\n",
        "    # define model\n",
        "    net = model.attention_net(topN=PROPOSAL_NUM, n_class=n_class)\n",
        "    if resume:\n",
        "        ckpt = torch.load(resume)\n",
        "        net.load_state_dict(ckpt['net_state_dict'])\n",
        "        start_epoch = ckpt['epoch'] + 1\n",
        "    creterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # define optimizers\n",
        "    raw_parameters = list(net.pretrained_model.parameters())\n",
        "    part_parameters = list(net.proposal_net.parameters())\n",
        "    concat_parameters = list(net.concat_net.parameters())\n",
        "    partcls_parameters = list(net.partcls_net.parameters())\n",
        "\n",
        "    raw_optimizer = torch.optim.SGD(raw_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
        "    concat_optimizer = torch.optim.SGD(concat_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
        "    part_optimizer = torch.optim.SGD(part_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
        "    partcls_optimizer = torch.optim.SGD(partcls_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
        "\n",
        "    schedulers = [MultiStepLR(raw_optimizer, milestones=[60, 100], gamma=0.1),\n",
        "                  MultiStepLR(concat_optimizer, milestones=[60, 100], gamma=0.1),\n",
        "                  MultiStepLR(part_optimizer, milestones=[60, 100], gamma=0.1),\n",
        "                  MultiStepLR(partcls_optimizer, milestones=[60, 100], gamma=0.1)]\n",
        "\n",
        "    if resume:\n",
        "        ckpt = torch.load(resume)\n",
        "        net.pretrained_model.load_state_dict({layer.replace('pretrained_model.', ''): ckpt['net_state_dict'][layer]\n",
        "                                              for layer in ckpt['net_state_dict'] if 'pretrained_model' in layer})\n",
        "\n",
        "        start_epoch = ckpt['epoch'] + 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX61jkgKiq5X"
      },
      "source": [
        "### Training Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV9XS6ODiq5X"
      },
      "outputs": [],
      "source": [
        "# Initialize\n",
        "if demo_mode == True:\n",
        "    END_EPOCH = 6\n",
        "else:\n",
        "    END_EPOCH = 500\n",
        "\n",
        "initialize_training()\n",
        "training_results = train(net=net,\n",
        "      batch_size=BATCH_SIZE,\n",
        "      proposal_num=PROPOSAL_NUM,\n",
        "      save_freq=SAVE_FREQ,\n",
        "      lr=LR,\n",
        "      wd=WD,\n",
        "      save_directory=save_dir,\n",
        "      resume_file=resume,\n",
        "      end_epoch=END_EPOCH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRUBD0bFiq5Y"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e29GorT1iq5Y"
      },
      "source": [
        "### Download Trained Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDueQNpOiq5Y"
      },
      "outputs": [],
      "source": [
        "# Download the existed model\n",
        "url = 'https://drive.google.com/uc?id=1vGOnn_KPy9InVgGdymivurewcWIK5f0X'\n",
        "output = 'model.pth'\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHq1f9L2iq5Y"
      },
      "source": [
        "### Define the Test Function and Run the Test\n",
        "\n",
        "Note: We utilize the model from the paper's GitHub repo for testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KErg-yuFiq5Y"
      },
      "outputs": [],
      "source": [
        "def test(model_path, net, testloader, creterion):\n",
        "    checkpoint = torch.load(model_path)\n",
        "    if 'net_state_dict' in checkpoint:\n",
        "        net.load_state_dict(checkpoint['net_state_dict'])\n",
        "    else:\n",
        "        net.load_state_dict(checkpoint)\n",
        "\n",
        "    net.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0\n",
        "    test_correct = 0\n",
        "    total = 0\n",
        "    auc_label_lst = []\n",
        "    auc_pred_lst = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            img, label, img_raw = data[0].cuda(), data[1].cuda(), data[2].cuda()\n",
        "            outputs = net(img, img_raw)\n",
        "\n",
        "            # Check outputs format, and select the right output if necessary\n",
        "            if isinstance(outputs, list):\n",
        "                outputs = outputs[0]  # Assuming the first element is the logits\n",
        "\n",
        "            loss = creterion(outputs, label)\n",
        "            test_loss += loss.item() * label.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            test_correct += (predicted == label).sum().item()\n",
        "            total += label.size(0)\n",
        "            auc_label_lst.append(label.cpu().numpy())\n",
        "            auc_pred_lst.append(outputs.softmax(dim=1).cpu().numpy())  # Using softmax to get probabilities for AUC\n",
        "\n",
        "    test_loss /= total\n",
        "    test_acc = test_correct / total\n",
        "    auc_score = roc_auc_score(np.concatenate(auc_label_lst), np.concatenate(auc_pred_lst, axis=0)[:, 1])\n",
        "\n",
        "    return {'loss': test_loss, 'accuracy': test_acc, 'auc': auc_score}\n",
        "\n",
        "model_path = 'model.pth'\n",
        "\n",
        "# Move model to GPU\n",
        "net = net.cuda()\n",
        "\n",
        "# Call the test function\n",
        "test_results = test(model_path, net, testloader, creterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX6bCcZNuxmz"
      },
      "source": [
        "# Evaluations and Results\n",
        "\n",
        "## Metrics Descriptions\n",
        "- The model is switched to evaluation mode using `net.eval()` to ensure that layers like dropout and batch normalization work in inference mode.\n",
        "- **Loss** is computed using the `criterion` which is typically a loss function suitable for classification tasks (e.g., cross-entropy loss) during the testing phase for each batch of data.\n",
        "- **Accuracy** is calculated by comparing the predicted and true labels to track the model's performance during testing.\n",
        "- Lists named `auc_label_lst` and `auc_pred_lst` suggest that the **Area Under the Curve (AUC)** metric is computed, which is common for binary classification tasks to evaluate the model's ability to distinguish between classes.\n",
        "- Using functions like `concat_loss` and `creterion` implies that the evaluation involves loss calculation, contributing to the overall measurement of the model's performance.\n",
        "\n",
        "This approach ensures that the model's performance is assessed using metrics that are standard in machine learning for classification tasks, providing insights into the generalizability and robustness of the model and aligning with common practices for evaluating deep learning models on classification problems using medical imaging data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXjUGrYriq5Y"
      },
      "source": [
        "## Define the Results Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjW9bCkouv8O"
      },
      "outputs": [],
      "source": [
        "def summarize_results(train_losses, val_losses, train_accuracies, val_accuracies, test_results):\n",
        "    # Calculate the final metrics\n",
        "    final_train_acc = train_accuracies[-1]\n",
        "    final_val_acc = val_accuracies[-1]\n",
        "    final_auc = test_results['auc']\n",
        "    final_accuracy = test_results['accuracy']\n",
        "    test_loss = test_results['loss']\n",
        "\n",
        "    # Print the summary of results\n",
        "    print(\"Final Training Accuracy: {:.2f}%\".format(final_train_acc * 100))\n",
        "    print(\"Final Validation Accuracy: {:.2f}%\".format(final_val_acc * 100))\n",
        "    print(\"Test Accuracy: {:.2f}%\".format(final_accuracy * 100))\n",
        "    print(\"Test AUC: {:.4f}\".format(final_auc))\n",
        "    print(\"Test Loss: {:.4f}\".format(test_loss))\n",
        "\n",
        "    # print(\"Test RMSE: {:.4f}\".format(final_rmse))\n",
        "\n",
        "    # Plotting the metrics\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.title('Loss over epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accuracies, label='Training Accuracy')\n",
        "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "    plt.title('Accuracy over epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvpdO2T5iq5Z"
      },
      "source": [
        "## Run the Evaluation and Display Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8C1HPvViq5Z"
      },
      "outputs": [],
      "source": [
        "summarize_results(training_results['train_losses'],\n",
        "                  training_results['test_losses'],\n",
        "                  training_results['train_accuracies'],\n",
        "                  training_results['test_accuracies'],\n",
        "                  test_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohUM16Qwiq5Z"
      },
      "source": [
        "## Results, Analysis and Plans\n",
        "\n",
        "### Results\n",
        "\n",
        "The replication attempt of the original study yielded notable outcomes. The final training accuracy was impressive at 69.09%. However, there was a significant drop in validation accuracy to 54.76%, which raises concerns. <br>\n",
        "The test accuracy (model loaded from GitHub repo) was remarkably high at 91.67%, paired with an AUC of 0.9324, which is usually indicative of a good model performance. However, the test loss was at a concerning 0.2566. The loss and accuracy graphs over epochs display a pattern where loss increases after an initial decrease, and accuracy seems to plateau, which might indicate issues with the model's learning capacity and its generalization to new data.\n",
        "\n",
        "### Analyses\n",
        "\n",
        "The training and validation loss trends in the graph show signs of overfitting, as evidenced by the training loss decreasing while the validation loss conversely increases after the initial epoch. This pattern suggests that the model may be memorizing the training data specifics instead of learning to generalize from them. Similarly, the accuracy graph does not show an expected increase in validation accuracy, which remains relatively flat, even as training accuracy improves. Although the AUC on the test set is high, the divergence between training and validation metrics cannot be overlooked.\n",
        "\n",
        "### Plans\n",
        "\n",
        "To address the concerns raised by the results and analyses, the following strategies are proposed to improve model performance and replication attempt:\n",
        "\n",
        "1. **Data Examination**: It is crucial to reassess the training and validation datasets to ensure they are representative and well-balanced. This reassessment might include augmenting the data, feature normalization, or removing potential biases that could affect model training.\n",
        "\n",
        "2. **Training Strategy**: To avoid overfitting and improve generalization, it might be beneficial to adopt more robust training strategies. These could include methods like cross-validation, using a different split for the training and validation datasets, or introducing regularization techniques.\n",
        "\n",
        "3. **Model Tuning**: The model's architecture and hyperparameters should be fine-tuned. This process can include experimenting with different network structures, activation functions, or learning rates.\n",
        "\n",
        "4. **Increased Iterations and Early Stopping**: Extending the number of training epochs might allow the model to learn better from the data. However, it's important to incorporate early stopping mechanisms to prevent overfitting. Monitoring the validation loss and accuracy can help determine the optimal point to stop training.\n",
        "\n",
        "These steps aim to enhance the model's ability to generalize and thus improve its performance on unseen data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EAWAy_LwHlV"
      },
      "source": [
        "## Model comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOdhGrbwwG71"
      },
      "outputs": [],
      "source": [
        "# compare you model with others\n",
        "# you don't need to re-run all other experiments, instead, you can directly refer the metrics/numbers in the paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH75TNU71eRH"
      },
      "source": [
        "# Discussion\n",
        "\n",
        "In this section,you should discuss your work and make future plan. The discussion should address the following questions:\n",
        "  * Make assessment that the paper is reproducible or not.\n",
        "  * Explain why it is not reproducible if your results are kind negative.\n",
        "  * Describe “What was easy” and “What was difficult” during the reproduction.\n",
        "  * Make suggestions to the author or other reproducers on how to improve the reproducibility.\n",
        "  * What will you do in next phase.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2VDXo5F4Frm"
      },
      "outputs": [],
      "source": [
        "# no code is required for this section\n",
        "'''\n",
        "if you want to use an image outside this notebook for explanaition,\n",
        "you can read and plot it here like the Scope of Reproducibility\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHMI2chl9omn"
      },
      "source": [
        "# References\n",
        "\n",
        "1.   Song Y, Zheng S, Li L, Zhang X, Zhang X, Huang Z, Chen J, Wang R, Zhao H, Chong Y, Shen J, Zha Y, Yang Y. Deep Learning Enables Accurate Diagnosis of Novel Coronavirus (COVID-19) With CT Images. IEEE/ACM Trans Comput Biol Bioinform. 2021 Nov-Dec;18(6):2775-2780. doi: 10.1109/TCBB.2021.3065361. Epub 2021 Dec 8. PMID: 33705321; PMCID: PMC8851430.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}