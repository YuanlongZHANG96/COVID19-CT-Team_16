{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YuanlongZHANG96/COVID19-CT-Team_16/blob/main/DL4H_Team_16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j01aH0PR4Sg-"
      },
      "source": [
        "# Final Project - Team 16\n",
        "\n",
        "- Paper Name: Deep learning enables accurate diagnosis of novel coronavirus (COVID-19) with CT images\n",
        "- Paper Link: https://www.medrxiv.org/content/10.1101/2020.02.23.20026930v1\n",
        "- GitHub Repo: https://github.com/biomed-AI/COVID19-CT\n",
        "\n",
        "---\n",
        "\n",
        "# FAQ and Attentions - TO BE REMOVED\n",
        "* Copy and move this template to your Google Drive. Name your notebook by your team ID (upper-left corner). Don't eidt this original file.\n",
        "* This template covers most questions we want to ask about your reproduction experiment. You don't need to exactly follow the template, however, you should address the questions. Please feel free to customize your report accordingly.\n",
        "* any report must have run-able codes and necessary annotations (in text and code comments).\n",
        "* The notebook is like a demo and only uses small-size data (a subset of original data or processed data), the entire runtime of the notebook including data reading, data process, model training, printing, figure plotting, etc,\n",
        "must be within 8 min, otherwise, you may get penalty on the grade.\n",
        "  * If the raw dataset is too large to be loaded  you can select a subset of data and pre-process the data, then, upload the subset or processed data to Google Drive and load them in this notebook.\n",
        "  * If the whole training is too long to run, you can only set the number of training epoch to a small number, e.g., 3, just show that the training is runable.\n",
        "  * For results model validation, you can train the model outside this notebook in advance, then, load pretrained model and use it for validation (display the figures, print the metrics).\n",
        "* The post-process is important! For post-process of the results,please use plots/figures. The code to summarize results and plot figures may be tedious, however, it won't be waste of time since these figures can be used for presentation. While plotting in code, the figures should have titles or captions if necessary (e.g., title your figure with \"Figure 1. xxxx\")\n",
        "* There is not page limit to your notebook report, you can also use separate notebooks for the report, just make sure your grader can access and run/test them.\n",
        "* If you use outside resources, please refer them (in any formats). Include the links to the resources if necessary."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjxq_goOiq5S"
      },
      "source": [
        "# Notebook Instructions\n",
        "- This notebook has been tested to run in Google Colab, with GPU (support CUDA) available.\n",
        "- The notebook may have a GPU issue when directly running in the Google Colab environment (Please consider upgrading to the paid version for more GPU available)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQ0sNuMePBXx"
      },
      "source": [
        "# Introduction - TO BE UPDATED\n",
        "\n",
        "## Background of the Problem\n",
        "- **Type of Problem**: The paper tackles diagnosing COVID-19 using computed tomography (CT) images, categorizing it under disease prediction and medical image analysis that leverages deep learning for feature extraction and classification.\n",
        "- **Importance/Meaning of Solving the Problem**: Accurate and rapid diagnosis of COVID-19 is crucial due to its fast spread and severe health implications. CT images are vital diagnostic tools, especially when other testing methods are constrained or slow. Enhancing diagnosis accuracy with AI supports timely treatment and aids in controlling the spread.\n",
        "- **Difficulty of the Problem**: Diagnosing is challenging due to the subtle differences between COVID-19 and other types of pneumonia visible in CT scans, which require highly accurate models capable of differentiating these fine details.\n",
        "- **State of the Art Methods and Effectiveness**: Before this study, methods such as standard convolutional neural networks (CNNs) were employed but did not achieve the accuracy needed for fine-grained classification required by CT images. This paper advances these methods by improving both accuracy and interpretability.\n",
        "\n",
        "## Paper Explanation\n",
        "- **Proposal**: The research introduces a deep learning-based CT diagnosis system named DRENet, designed to enhance COVID-19 diagnosis from CT images. It incorporates ResNet50 with a Feature Pyramid Network (FPN) for improved feature extraction at multiple scales.\n",
        "- **Innovations of the Method**: The innovation resides in merging deep learning techniques with attention mechanisms to better detect and classify COVID-19 features in CT scans. Utilizing FPN allows detecting lesions at various scales, thus boosting the model’s ability to identify pertinent features across diverse image presentations.\n",
        "- **Effectiveness of the Proposed Method**: The method showed high effectiveness with an AUC (Area Under the Curve) of 0.95, recall of 0.96, and precision of 0.79, indicating a robust capability to distinguish between COVID-19 and bacterial pneumonia, which are frequently confused in clinical settings.\n",
        "- **Contribution to the Research Regime**: The paper's contribution is noteworthy as it not only increases the accuracy of COVID-19 diagnosis through imaging but also aids the interpretability of AI in medical diagnostics, essential for clinical acceptance where comprehending the AI's decision-making process can assist physicians in making informed decisions.\n",
        "\n",
        "This holistic approach not only pushes forward the technology in medical diagnostics but also sets a foundation for future research into AI applications in medicine, particularly in improving the reliability and usability of such systems in real-world clinical environments.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uygL9tTPSVHB"
      },
      "source": [
        "# Scope of Reproducibility - TODO:\n",
        "\n",
        "List hypotheses from the paper you will test and the corresponding experiments you will run.\n",
        "\n",
        "\n",
        "1.   Hypothesis 1: xxxxxxx\n",
        "2.   Hypothesis 2: xxxxxxx\n",
        "\n",
        "You can insert images in this notebook text, [see this link](https://stackoverflow.com/questions/50670920/how-to-insert-an-inline-image-in-google-colaboratory-from-google-drive) and example below:\n",
        "\n",
        "![sample_image.png](https://drive.google.com/uc?export=view&id=1g2efvsRJDxTxKz-OY3loMhihrEUdBxbc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWAHJ_1CdtaA"
      },
      "source": [
        "# Methodology\n",
        "\n",
        "This methodology is the core of your project. It consists of run-able codes with necessary annotations to show the expeiment you executed for testing the hypotheses.\n",
        "\n",
        "The methodology at least contains two subsections **data** and **model** in your experiment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5EZ3yugiq5T"
      },
      "source": [
        "### Environment and Packages\n",
        "#### Import the Published Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6lA7ZvyYiq5T"
      },
      "outputs": [],
      "source": [
        "# Please un comment and run all installation if you don't have package\n",
        "#!pip install requests numpy torch scikit-learn gdown matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yu61Jp1xrnKk"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from datetime import datetime\n",
        "import pickle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.utils.data\n",
        "from torch.nn import DataParallel\n",
        "from torch.optim.lr_scheduler import MultiStepLR\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import roc_auc_score, mean_squared_error\n",
        "from math import sqrt\n",
        "import gdown\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RnvWUKY7iq5U"
      },
      "source": [
        "#### Download and Import the Private Packages\n",
        "- Define the download functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dfh10aseiq5U"
      },
      "outputs": [],
      "source": [
        "# https://drive.google.com/file/d/1sSbRS4-cNyATJbwqpe97YvGG8qZkulTG/view?usp=sharing\n",
        "# Function to download and unzip files from GitHub into a target directory\n",
        "def download_and_unzip(url, target_folder):\n",
        "    response = requests.get(url, stream=True)\n",
        "    if response.status_code == 200:\n",
        "        zipfile_path = os.path.join(target_folder, 'temp.zip')\n",
        "        with open(zipfile_path, 'wb') as f:\n",
        "            f.write(response.content)\n",
        "        with zipfile.ZipFile(zipfile_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(target_folder)\n",
        "        os.remove(zipfile_path)  # Clean up temp file\n",
        "    else:\n",
        "        print(f\"Failed to download from {url}\")\n",
        "\n",
        "# Function to download and unzip files from Google Drive to target directory\n",
        "def gdown_and_unzip(file_id, output, target_folder):\n",
        "    os.makedirs(target_folder, exist_ok=True)  # Create the target folder if it doesn't exist\n",
        "    zipfile_path = os.path.join(target_folder, output)\n",
        "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
        "    gdown.download(url, zipfile_path, quiet=False)\n",
        "\n",
        "    with zipfile.ZipFile(zipfile_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(target_folder)\n",
        "\n",
        "    os.remove(zipfile_path)  # Clean up temp file\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsCEZvnDiq5V"
      },
      "source": [
        "- Call the functionds and import the private packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsLPWAUViq5V"
      },
      "outputs": [],
      "source": [
        "# Download and extract the ZIP file\n",
        "file_id = \"1sSbRS4-cNyATJbwqpe97YvGG8qZkulTG\"\n",
        "output = \"core.zip\"\n",
        "target_folder = '.'\n",
        "\n",
        "gdown_and_unzip(file_id, output, target_folder)\n",
        "\n",
        "# Import the required functions from downloaded packages\n",
        "from core import model, dataset\n",
        "from core.config import BATCH_SIZE, PROPOSAL_NUM, SAVE_FREQ, LR, WD, resume, save_dir\n",
        "from core.utils import init_log, progress_bar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Si8DLgMAiq5V"
      },
      "source": [
        "### Mode Setup\n",
        "**demo_mode**\n",
        "- If **True**: We will use a small data sample and training in short time;\n",
        "- If **False**, we will download original data and training for regular time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0IK_1kz2iq5V"
      },
      "outputs": [],
      "source": [
        "demo_mode = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NbPHUTMbkD3"
      },
      "source": [
        "##  Data - TODO\n",
        "Data includes raw data (MIMIC III tables), descriptive statistics (our homework questions), and data processing (feature engineering).\n",
        "  * Source of the data: where the data is collected from; if data is synthetic or self-generated, explain how. If possible, please provide a link to the raw datasets.\n",
        "  * Statistics: include basic descriptive statistics of the dataset like size, cross validation split, label distribution, etc.\n",
        "  * Data process: how do you munipulate the data, e.g., change the class labels, split the dataset to train/valid/test, refining the dataset.\n",
        "  * Illustration: printing results, plotting figures for illustration.\n",
        "  * You can upload your raw dataset to Google Drive and mount this Colab to the same directory. If your raw dataset is too large, you can upload the processed dataset and have a code to load the processed dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzVUQS0CHry0"
      },
      "source": [
        "### Load the Data Depends on Mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZScZNbROw-N"
      },
      "outputs": [],
      "source": [
        "raw_data_dir = \"\"\n",
        "\n",
        "# Call the data loading based on different mode\n",
        "# If use demo mode, we will download small dataset from google drive;\n",
        "# If use regular mode, we will download complete dataset from orginal github repo.\n",
        "if demo_mode == False:\n",
        "    # URLs\n",
        "    url_prefix = \"https://github.com/biomed-AI/COVID19-CT/blob/a7f9e65cc2c1dd699b010a8963f6923b9b426ae4/local_traniner/input\"\n",
        "    test_zip_url = url_prefix + \"/test.zip?raw=true\"\n",
        "    train_zip_url = url_prefix + \"/train.zip?raw=true\"\n",
        "    val_zip_url = url_prefix + \"/val.zip?raw=true\"\n",
        "\n",
        "    # Path to the target folder\n",
        "    target_folder = './input_complete'\n",
        "\n",
        "    # Ensure the target directory exists\n",
        "    os.makedirs(target_folder, exist_ok=True)\n",
        "\n",
        "    # Download and unzip each file\n",
        "    download_and_unzip(test_zip_url, target_folder)\n",
        "    download_and_unzip(train_zip_url, target_folder)\n",
        "    download_and_unzip(val_zip_url, target_folder)\n",
        "else:\n",
        "    file_id = \"1N2k3Sm3m7aKNQE1b9AbcGrknRzJdvT90\"\n",
        "    output = \"input.zip\"\n",
        "    target_folder = './input'\n",
        "    gdown_and_unzip(file_id, output, target_folder)\n",
        "\n",
        "\n",
        "def load_image_data():\n",
        "    # Load the image folders\n",
        "    if demo_mode == True:\n",
        "        train_path = './input/train/'\n",
        "        val_path = './input/val/'\n",
        "        test_path = './input/test/'\n",
        "    else:\n",
        "        train_path = './input_complete/train/'\n",
        "        val_path = './input_complete/val/'\n",
        "        test_path = './input_complete/test/'\n",
        "\n",
        "    trainset = dataset.SARS(root=train_path, is_train=True)\n",
        "    valset = dataset.SARS(root=val_path, is_train=False)\n",
        "    testset = dataset.SARS(root=test_path, is_train=False)\n",
        "    return trainset, valset, testset\n",
        "\n",
        "# Load raw data\n",
        "trainset, valset, testset = load_image_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zn3pTDskiq5W"
      },
      "source": [
        "### Calculate Statistics of Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dFeMyOcviq5W"
      },
      "outputs": [],
      "source": [
        "# calculate statistics\n",
        "def calculate_stats(trainset, valset, testset):\n",
        "  # implement this function to calculate the statistics\n",
        "  # it is encouraged to print out the results\n",
        "\n",
        "    # Calculate the number of samples in each set\n",
        "    num_train_samples = len(trainset)\n",
        "    num_val_samples = len(valset)\n",
        "    num_test_samples = len(testset)\n",
        "\n",
        "    print(f'Number of training samples: {num_train_samples}')\n",
        "    print(f'Number of validation samples: {num_val_samples}')\n",
        "    print(f'Number of test samples: {num_test_samples}')\n",
        "\n",
        "calculate_stats(trainset, valset, testset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3muyDPFPbozY"
      },
      "source": [
        "##   Model - TODO\n",
        "The model includes the model definitation which usually is a class, model training, and other necessary parts.\n",
        "  * Model architecture: layer number/size/type, activation function, etc\n",
        "  * Training objectives: loss function, optimizer, weight of each loss term, etc\n",
        "  * Others: whether the model is pretrained, Monte Carlo simulation for uncertainty analysis, etc\n",
        "  * The code of model should have classes of the model, functions of model training, model validation, etc.\n",
        "  * If your model training is done outside of this notebook, please upload the trained model here and develop a function to load and test it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JcKHtHU79Iy"
      },
      "source": [
        "### The Models\n",
        "- The model we use is from model.py in core folder, which we directly imported at the begining."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JTSCvP9iq5W"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcDBj6p2Cj7X"
      },
      "source": [
        "### Define the Training Process\n",
        "- We deploy the training process to ensure it can run in the local environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBdVZoTvsSFV",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "# Initialize Variable\n",
        "save_dir1 = './'\n",
        "\n",
        "# Define Training Process\n",
        "def train(batch_size, proposal_num, save_freq, lr, wd, resume_file, save_directory, net, end_epoch):\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "    start_epoch = 1\n",
        "    save_dir = os.path.join(save_directory, datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
        "\n",
        "    import torch\n",
        "    print(torch.__version__)\n",
        "    print(torch.cuda.is_available())\n",
        "    print(torch.version.cuda)\n",
        "\n",
        "    net = net.cuda()\n",
        "    net = DataParallel(net)\n",
        "\n",
        "    train_losses = []\n",
        "    test_losses = []\n",
        "    train_accuracies = []\n",
        "    test_accuracies = []\n",
        "\n",
        "    skip_epoch = 0\n",
        "\n",
        "    for epoch in range(start_epoch, end_epoch):\n",
        "        if epoch > skip_epoch:\n",
        "            add = True\n",
        "        else:\n",
        "            add = False\n",
        "        for scheduler in schedulers:\n",
        "            scheduler.step()\n",
        "\n",
        "        # begin training\n",
        "        _print('--' * 50)\n",
        "        net.train()\n",
        "        train_correct = 0\n",
        "        total = 0\n",
        "        for i, data in enumerate(trainloader):\n",
        "            img, label, img_raw = data[0].cuda(), data[1].cuda(), data[2]\n",
        "            batch_size = img.size(0)\n",
        "            raw_optimizer.zero_grad()\n",
        "            part_optimizer.zero_grad()\n",
        "            concat_optimizer.zero_grad()\n",
        "            partcls_optimizer.zero_grad()\n",
        "            raw_logits, concat_logits, part_logits, _, top_n_prob = net(img, img_raw, add)\n",
        "            part_loss = model.list_loss(part_logits.view(batch_size * PROPOSAL_NUM, -1),\n",
        "                                        label.unsqueeze(1).repeat(1, PROPOSAL_NUM).view(-1)).view(batch_size, PROPOSAL_NUM)\n",
        "            raw_loss = creterion(raw_logits, label)\n",
        "            concat_loss = creterion(concat_logits, label)\n",
        "            rank_loss = model.ranking_loss(top_n_prob, part_loss)\n",
        "            partcls_loss = creterion(part_logits.view(batch_size * PROPOSAL_NUM, -1),\n",
        "                                     label.unsqueeze(1).repeat(1, PROPOSAL_NUM).view(-1))\n",
        "\n",
        "            total_loss = raw_loss + rank_loss + concat_loss + partcls_loss\n",
        "            total_loss.backward()\n",
        "            raw_optimizer.step()\n",
        "            part_optimizer.step()\n",
        "            concat_optimizer.step()\n",
        "            partcls_optimizer.step()\n",
        "            progress_bar(i, len(trainloader), 'train')\n",
        "\n",
        "            _, concat_predict = torch.max(concat_logits, 1)\n",
        "            total += batch_size\n",
        "            train_correct += torch.sum(concat_predict.data == label.data)\n",
        "\n",
        "        print(float(train_correct) / total)\n",
        "        pickle.dump(net, open('./model.pkl', 'wb'))\n",
        "        if epoch % SAVE_FREQ == 0 :#and epoch > 20:\n",
        "            train_loss = 0\n",
        "            train_correct = 0\n",
        "            total = 0\n",
        "            net.eval()\n",
        "            auc_label_lst = []\n",
        "            auc_pred_lst = []\n",
        "            people_lst = []\n",
        "            file_name_lst = []\n",
        "            for i, data in enumerate(valloader):\n",
        "                with torch.no_grad():\n",
        "                    img, label, img_raw = data[0].cuda(), data[1].cuda(), data[2]\n",
        "                    batch_size = img.size(0)\n",
        "                    _, concat_logits, _, _, _, = net(img, img_raw, add)\n",
        "                    # calculate loss\n",
        "                    concat_loss = creterion(concat_logits, label)\n",
        "                    # calculate accuracy\n",
        "                    _, concat_predict = torch.max(concat_logits, 1)\n",
        "                    auc_label_lst += list(label.data.cpu().numpy())\n",
        "                    pred = torch.nn.Softmax(1)(concat_logits)\n",
        "                    auc_pred_lst.append(pred.data.cpu().numpy())\n",
        "                    people_lst.append(data[3])\n",
        "                    file_name_lst.append(data[4])\n",
        "\n",
        "                    total += batch_size\n",
        "                    train_correct += torch.sum(concat_predict.data == label.data)\n",
        "                    train_loss += concat_loss.item() * batch_size\n",
        "                    progress_bar(i, len(valloader), 'eval train set')\n",
        "            train_acc = float(train_correct) / total\n",
        "            train_loss = train_loss / total\n",
        "\n",
        "            # For final reporting purposes\n",
        "            train_losses.append(train_loss)\n",
        "            train_accuracies.append(train_acc)\n",
        "\n",
        "            _print(\n",
        "                'epoch:{} - train loss: {:.3f} and train acc: {:.3f} total sample: {}'.format(\n",
        "                    epoch,\n",
        "                    train_loss,\n",
        "                    train_acc,\n",
        "                    total))\n",
        "\n",
        "            print(f'auc: {roc_auc_score(auc_label_lst, np.concatenate(auc_pred_lst, 0)[:, 1]):.4f}')\n",
        "            np.save('./train_pred.npy', np.concatenate(auc_pred_lst, 0))\n",
        "            np.save('./train_label.npy', np.array(auc_label_lst))\n",
        "            np.save('./train_people.npy', np.concatenate(people_lst, 0))\n",
        "            np.save('./train_file_name.npy', np.concatenate(file_name_lst, 0))\n",
        "        # evaluate on test set\n",
        "            test_loss = 0\n",
        "            test_correct = 0\n",
        "            total = 0\n",
        "            auc_label_lst = []\n",
        "            auc_pred_lst = []\n",
        "            people_lst = []\n",
        "            img_vis_lst = []\n",
        "            file_name_lst = []\n",
        "            anchor_lst = []\n",
        "            for i, data in enumerate(testloader):\n",
        "    # =============================================================================\n",
        "    #             if i < 1:\n",
        "    #                 continue\n",
        "    # =============================================================================\n",
        "                with torch.no_grad():\n",
        "                    img, label, img_raw = data[0].cuda(), data[1].cuda(), data[2]\n",
        "                    batch_size = img.size(0)\n",
        "                    _, concat_logits, _, _, _ = net(img, img_raw, add, False)\n",
        "                    # calculate loss\n",
        "                    concat_loss = creterion(concat_logits, label)\n",
        "                    # calculate accuracy\n",
        "                    _, concat_predict = torch.max(concat_logits, 1)\n",
        "                    auc_label_lst += list(label.data.cpu().numpy())\n",
        "                    pred = torch.nn.Softmax(1)(concat_logits)\n",
        "                    auc_pred_lst.append(pred.data.cpu().numpy())\n",
        "                    people_lst.append(data[3])\n",
        "                    file_name_lst += list(data[4])\n",
        "    # =============================================================================\n",
        "    #                 img_vis_lst.append(img_vis)\n",
        "    #                 anchor_lst.append(anchor)\n",
        "    # =============================================================================\n",
        "\n",
        "                    total += batch_size\n",
        "                    test_correct += torch.sum(concat_predict.data == label.data)\n",
        "                    test_loss += concat_loss.item() * batch_size\n",
        "                    progress_bar(i, len(testloader), 'eval test set')\n",
        "            test_acc = float(test_correct) / total\n",
        "            test_loss = test_loss / total\n",
        "\n",
        "            # Final eval purposes\n",
        "            test_losses.append(test_loss)\n",
        "            test_accuracies.append(test_acc)\n",
        "\n",
        "            _print(\n",
        "                'epoch:{} - test loss: {:.3f} and test acc: {:.3f} total sample: {}'.format(\n",
        "                    epoch,\n",
        "                    test_loss,\n",
        "                    test_acc,\n",
        "                    total))\n",
        "\n",
        "\n",
        "            print(f'auc: {roc_auc_score(auc_label_lst, np.concatenate(auc_pred_lst, 0)[:, 1]):.4f}')\n",
        "            np.save('./test_pred.npy', np.concatenate(auc_pred_lst, 0))\n",
        "            np.save('./test_label.npy', np.array(auc_label_lst))\n",
        "            np.save('./test_people.npy', np.concatenate(people_lst, 0))\n",
        "            np.save('./test_file_name.npy', np.array(file_name_lst))\n",
        "\n",
        "    # =============================================================================\n",
        "    #         np.save('./test_anchor_lst.npy', np.concatenate(anchor_lst, 0))\n",
        "    #         np.save('./test_vis.npy', np.concatenate(img_vis_lst, 0))\n",
        "    #         assert 0\n",
        "    # =============================================================================\n",
        "        # save model\n",
        "            net_state_dict = net.module.state_dict()\n",
        "            if not os.path.exists(save_dir):\n",
        "                os.mkdir(save_dir)\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'train_loss': train_loss,\n",
        "                'train_acc': train_acc,\n",
        "                'test_loss': test_loss,\n",
        "                'test_acc': test_acc,\n",
        "                'net_state_dict': net_state_dict},\n",
        "                os.path.join(save_dir, '%03d.ckpt' % epoch))\n",
        "    # =============================================================================\n",
        "    #         assert 0\n",
        "    # =============================================================================\n",
        "    print('finishing training')\n",
        "    # Store final results in a dictionary\n",
        "    training_results = {\n",
        "        'train_losses': train_losses,\n",
        "        'test_losses': test_losses,\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'test_accuracies': test_accuracies\n",
        "    }\n",
        "\n",
        "    return training_results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6q0Ehnmiq5X"
      },
      "source": [
        "### Initialize the Training Session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUnLMT78iq5X"
      },
      "outputs": [],
      "source": [
        "# Initialize the training model\n",
        "def initialize_training():\n",
        "    global net, trainloader, valloader, testloader, creterion, raw_optimizer, concat_optimizer, part_optimizer, partcls_optimizer, schedulers, _print, start_epoch, save_dir\n",
        "    os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
        "    start_epoch = 1\n",
        "    save_dir = os.path.join(save_dir1, datetime.now().strftime('%Y%m%d_%H%M%S'))\n",
        "    if os.path.exists(save_dir):\n",
        "        raise NameError('model dir exists!')\n",
        "    os.makedirs(save_dir)\n",
        "    logging = init_log(save_dir)\n",
        "    _print = logging.info\n",
        "\n",
        "    # read dataset\n",
        "\n",
        "    if demo_mode == True:\n",
        "        train_path = './input/train/'\n",
        "        val_path = './input/val/'\n",
        "        test_path = './input/test/'\n",
        "    else:\n",
        "        train_path = './input_complete/train/'\n",
        "        val_path = './input_complete/val/'\n",
        "        test_path = './input_complete/test/'\n",
        "\n",
        "    trainset = dataset.SARS(root=train_path, is_train=True)\n",
        "    valset = dataset.SARS(root=val_path, is_train=False)\n",
        "    testset = dataset.SARS(root=test_path, is_train=False)\n",
        "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=BATCH_SIZE,\n",
        "                                              shuffle=True, num_workers=8, drop_last=False)\n",
        "    testloader = torch.utils.data.DataLoader(testset, batch_size=BATCH_SIZE,\n",
        "                                             shuffle=False, num_workers=8, drop_last=False)\n",
        "    valloader = torch.utils.data.DataLoader(valset, batch_size=BATCH_SIZE,\n",
        "                                            shuffle=False, num_workers=8, drop_last=False)\n",
        "\n",
        "    n_class = 2\n",
        "    # define model\n",
        "    net = model.attention_net(topN=PROPOSAL_NUM, n_class=n_class)\n",
        "    if resume:\n",
        "        ckpt = torch.load(resume)\n",
        "        net.load_state_dict(ckpt['net_state_dict'])\n",
        "        start_epoch = ckpt['epoch'] + 1\n",
        "    creterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # define optimizers\n",
        "    raw_parameters = list(net.pretrained_model.parameters())\n",
        "    part_parameters = list(net.proposal_net.parameters())\n",
        "    concat_parameters = list(net.concat_net.parameters())\n",
        "    partcls_parameters = list(net.partcls_net.parameters())\n",
        "\n",
        "    raw_optimizer = torch.optim.SGD(raw_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
        "    concat_optimizer = torch.optim.SGD(concat_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
        "    part_optimizer = torch.optim.SGD(part_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
        "    partcls_optimizer = torch.optim.SGD(partcls_parameters, lr=LR, momentum=0.9, weight_decay=WD)\n",
        "\n",
        "    schedulers = [MultiStepLR(raw_optimizer, milestones=[60, 100], gamma=0.1),\n",
        "                  MultiStepLR(concat_optimizer, milestones=[60, 100], gamma=0.1),\n",
        "                  MultiStepLR(part_optimizer, milestones=[60, 100], gamma=0.1),\n",
        "                  MultiStepLR(partcls_optimizer, milestones=[60, 100], gamma=0.1)]\n",
        "\n",
        "    if resume:\n",
        "        ckpt = torch.load(resume)\n",
        "        net.pretrained_model.load_state_dict({layer.replace('pretrained_model.', ''): ckpt['net_state_dict'][layer]\n",
        "                                              for layer in ckpt['net_state_dict'] if 'pretrained_model' in layer})\n",
        "\n",
        "        start_epoch = ckpt['epoch'] + 1\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX61jkgKiq5X"
      },
      "source": [
        "### Training Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LV9XS6ODiq5X"
      },
      "outputs": [],
      "source": [
        "# Initialize\n",
        "if demo_mode == True:\n",
        "    END_EPOCH = 6\n",
        "else:\n",
        "    END_EPOCH = 500\n",
        "\n",
        "initialize_training()\n",
        "training_results = train(net=net,\n",
        "      batch_size=BATCH_SIZE,\n",
        "      proposal_num=PROPOSAL_NUM,\n",
        "      save_freq=SAVE_FREQ,\n",
        "      lr=LR,\n",
        "      wd=WD,\n",
        "      save_directory=save_dir,\n",
        "      resume_file=resume,\n",
        "      end_epoch=END_EPOCH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRUBD0bFiq5Y"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e29GorT1iq5Y"
      },
      "source": [
        "### Download Trained Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jDueQNpOiq5Y"
      },
      "outputs": [],
      "source": [
        "# Download the existed model\n",
        "url = 'https://drive.google.com/uc?id=1vGOnn_KPy9InVgGdymivurewcWIK5f0X'\n",
        "output = 'model.pth'\n",
        "gdown.download(url, output, quiet=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHq1f9L2iq5Y"
      },
      "source": [
        "### Define the Test Function and Run the Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KErg-yuFiq5Y"
      },
      "outputs": [],
      "source": [
        "def test(model_path, net, testloader, creterion):\n",
        "    checkpoint = torch.load(model_path)\n",
        "    if 'net_state_dict' in checkpoint:\n",
        "        net.load_state_dict(checkpoint['net_state_dict'])\n",
        "    else:\n",
        "        net.load_state_dict(checkpoint)\n",
        "\n",
        "    net.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0\n",
        "    test_correct = 0\n",
        "    total = 0\n",
        "    auc_label_lst = []\n",
        "    auc_pred_lst = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for data in testloader:\n",
        "            img, label, img_raw = data[0].cuda(), data[1].cuda(), data[2].cuda()\n",
        "            outputs = net(img, img_raw)\n",
        "\n",
        "            # Check outputs format, and select the right output if necessary\n",
        "            if isinstance(outputs, list):\n",
        "                outputs = outputs[0]  # Assuming the first element is the logits\n",
        "\n",
        "            loss = creterion(outputs, label)\n",
        "            test_loss += loss.item() * label.size(0)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            test_correct += (predicted == label).sum().item()\n",
        "            total += label.size(0)\n",
        "            auc_label_lst.append(label.cpu().numpy())\n",
        "            auc_pred_lst.append(outputs.softmax(dim=1).cpu().numpy())  # Using softmax to get probabilities for AUC\n",
        "\n",
        "    test_loss /= total\n",
        "    test_acc = test_correct / total\n",
        "    auc_score = roc_auc_score(np.concatenate(auc_label_lst), np.concatenate(auc_pred_lst, axis=0)[:, 1])\n",
        "\n",
        "    return {'loss': test_loss, 'accuracy': test_acc, 'auc': auc_score}\n",
        "\n",
        "model_path = 'model.pth'\n",
        "\n",
        "# Move model to GPU\n",
        "net = net.cuda()\n",
        "\n",
        "# Call the test function\n",
        "test_results = test(model_path, net, testloader, creterion)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX6bCcZNuxmz"
      },
      "source": [
        "# Results - TO BE UPDATED\n",
        "In this section, you should finish training your model training or loading your trained model. That is a great experiment! You should share the results with others with necessary metrics and figures.\n",
        "\n",
        "Please test and report results for all experiments that you run with:\n",
        "\n",
        "*   specific numbers (accuracy, AUC, RMSE, etc)\n",
        "*   figures (loss shrinkage, outputs from GAN, annotation or label of sample pictures, etc)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXjUGrYriq5Y"
      },
      "source": [
        "## Define the Results Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjW9bCkouv8O"
      },
      "outputs": [],
      "source": [
        "def summarize_results(train_losses, val_losses, train_accuracies, val_accuracies, test_results):\n",
        "    # Calculate the final metrics\n",
        "    final_train_acc = train_accuracies[-1]\n",
        "    final_val_acc = val_accuracies[-1]\n",
        "    final_auc = test_results['auc']\n",
        "    final_accuracy = test_results['accuracy']\n",
        "    test_loss = test_results['loss']\n",
        "\n",
        "    # Print the summary of results\n",
        "    print(\"Final Training Accuracy: {:.2f}%\".format(final_train_acc * 100))\n",
        "    print(\"Final Validation Accuracy: {:.2f}%\".format(final_val_acc * 100))\n",
        "    print(\"Test Accuracy: {:.2f}%\".format(final_accuracy * 100))\n",
        "    print(\"Test AUC: {:.4f}\".format(final_auc))\n",
        "    print(\"Test Loss: {:.4f}\".format(test_loss))\n",
        "\n",
        "    # print(\"Test RMSE: {:.4f}\".format(final_rmse))\n",
        "\n",
        "    # Plotting the metrics\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_losses, label='Training Loss')\n",
        "    plt.plot(val_losses, label='Validation Loss')\n",
        "    plt.title('Loss over epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accuracies, label='Training Accuracy')\n",
        "    plt.plot(val_accuracies, label='Validation Accuracy')\n",
        "    plt.title('Accuracy over epochs')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvpdO2T5iq5Z"
      },
      "source": [
        "## Run the Evaluation and Display Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U8C1HPvViq5Z"
      },
      "outputs": [],
      "source": [
        "summarize_results(training_results['train_losses'],\n",
        "                  training_results['test_losses'],\n",
        "                  training_results['train_accuracies'],\n",
        "                  training_results['test_accuracies'],\n",
        "                  test_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohUM16Qwiq5Z"
      },
      "source": [
        "## Results, Analysis and Plans\n",
        "\n",
        "### Results\n",
        "The replication attempt of the original study yielded a final training accuracy of 69.09%, with a drop in validation accuracy to 53.57%. The test accuracy was 54.76%, with an AUC of 0.6569 and a test loss of 1.6631. The loss and accuracy graphs over epochs show a trend of increasing loss and plateauing accuracy, indicating potential issues with the model's learning and generalization capability.\n",
        "\n",
        "### Analyses\n",
        "The loss graph demonstrates an overfitting trend, with the training loss decreasing while the validation loss increases. This divergence suggests that the model is memorizing the training data rather than learning features generalizable to unseen data. The accuracy graph supports this, as the validation accuracy does not improve in tandem with the training accuracy. The suboptimal AUC value further indicates that the model's ability to distinguish between classes is limited.\n",
        "\n",
        "### Plans\n",
        "Given these results, the following plan is proposed to improve the replication attempt:\n",
        "\n",
        "- **Data Examination**: Reassess the data used for training and validation to ensure it is representative and balanced.\n",
        "- **Training Strategy**: Implement a more robust training strategy, such as cross-validation or a different split of the data, to increase the model's ability to generalize.\n",
        "- **Increased Iterations**: Extend the number of epochs while incorporating early stopping mechanisms to find a better balance between learning and overfitting.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8EAWAy_LwHlV"
      },
      "source": [
        "## Model comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOdhGrbwwG71"
      },
      "outputs": [],
      "source": [
        "# compare you model with others\n",
        "# you don't need to re-run all other experiments, instead, you can directly refer the metrics/numbers in the paper"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qH75TNU71eRH"
      },
      "source": [
        "# Discussion\n",
        "\n",
        "In this section,you should discuss your work and make future plan. The discussion should address the following questions:\n",
        "  * Make assessment that the paper is reproducible or not.\n",
        "  * Explain why it is not reproducible if your results are kind negative.\n",
        "  * Describe “What was easy” and “What was difficult” during the reproduction.\n",
        "  * Make suggestions to the author or other reproducers on how to improve the reproducibility.\n",
        "  * What will you do in next phase.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2VDXo5F4Frm"
      },
      "outputs": [],
      "source": [
        "# no code is required for this section\n",
        "'''\n",
        "if you want to use an image outside this notebook for explanaition,\n",
        "you can read and plot it here like the Scope of Reproducibility\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHMI2chl9omn"
      },
      "source": [
        "# References\n",
        "\n",
        "1.   Sun, J, [paper title], [journal title], [year], [volume]:[issue], doi: [doi link to paper]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmVuzQ724HbO"
      },
      "source": [
        "# Feel free to add new sections"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}